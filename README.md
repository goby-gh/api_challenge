# Backend Software Challenge
For Habitat Energy  
Author: NoahMaze@ieee.org

## Usage
Run the demo: `docker compose up`

Docker will build the images, migrate the database, and kick off the work described in the challenge problem (hit the api, save the data, exit).

Verify that the data was saved by running this in another terminal on the host:
```bash
docker compose exec -it db \
  psql \
    -U postgres\
    -d habitat\
    -c " select * from noah.auction_results;"
```

The information below this section is for context, and is not necessary for running the demo.

## Docker Images
This demo has two containers, the database and the python app.

### Postgres
This database container automatically runs database migrations the first time it is started.  The migrations are stored in migrations.sql.

The migration file was generated by calling `docker compose exec app flask --app challenge:app db upgrade --sql > db/migrations.sql` on the host system.  This SQL file does not need to be regenerated unless the data model changes.  (See "Changing the data model" in the __Misc Notes__ section)

The data is saved in the `noah` schema on the `habitat` database.
The schema migrations are generated automatically by alembic and saved to `db/migrations.sql`.

### App
Hits the API, saves the data, and exits.  
The data model is in `models.py`
API Integration is in `api.py`
The docker entrypoint is in `challenge.py`

## Docker Compose
Defines a `db` container and an `app` container, and shares the local directory with them.

## Python Modules

### api.py
Interacts with the Dynamic Containment API.  Returns JSON

### models.py
Describes the data model for the system, and holds the logic to generate an AuctionResult record from the API's json.

### challenge.py
Configures a flask app (to coordinate database migrations and the ORM).  Pulls data from the API and saves it to the database.

## Future work
* Clean up the types in models.py to match incoming data and save space.
  * varchar limits,
  * correct bit depth on integers
  * Numeric precision
  * Codify truly nullable types
  * First class support for "tsvector" instead of coercing to text  
* Use logger instead of print statements
* Extend the data model to include the entire life cycle of an auction, and use foreign keys to link auctions to results (and link auctions to location- and/or unit-records)
* Write tests!

## Misc notes

### Changing the data model
Updating the data model is a 3 step process:
1. Update the definition of the data model in `models.py`
2. Generate a migration by running `flask --app challenge:app db migrate` in the `app` container
3. Dump the migration to a SQL file so it can be included in future `docker compose build`s by running the following command on the host:
```bash
docker compose exec app \
  flask --app challenge:app \
  db upgrade --sql > db/migrations.sql   
```

### Initializing Alembic
Initialize alembic (once per project) with: `flask --app challenge:app db init`

### Additional useful commands
Generate a Migration:
`flask --app challenge:app db migrate -m "Add Auction Results model"`

Dump Migration SQL:
`flask --app challenge:app db upgrade --sql`

dump migration sql file (from host):
`docker compose exec app flask --app challenge:app db upgrade --sql > db/migrations.sql`

Destroy compose environment AND volumes (clears postgres data) `docker compose down -v`

Remove volumes, rebuild, and start the compose again:
```bash
 docker compose down -v && docker compose build && docker compose up
 ```
